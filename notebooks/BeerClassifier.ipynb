{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beer Classifier üçª üçª üçª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Imagine the scenario:\n",
    "\n",
    "> You're standing in the supermarket looking at the shelf of beers. You're taken aback by the shear amount of options and you don't know which one to buy. You wish you could get some sort of help identifying all of these beers.\n",
    "\n",
    "This happens way to often and this need to be fixed! Introducing: **THE BEER CLASSIFIER**\n",
    "\n",
    "<img src=\"images/personal_care.jpg\" style=\"height:350px;\">\n",
    "<caption><center> <u> Figure 1:</u> A shelf of beers in a Danish supermarket<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scope of this notebook\n",
    "This notebook is meant as a self-paced walkthrough for constructing `The Beer Classifier` which is a `Convolutional Neural Network` (CNN) able to detect if an image contains a Hoegaarden (see Figure 2) or a Tuborg (see Figure 3). The goal of is to construct and train this CNN from scratch.\n",
    "\n",
    "This notebook will give a high-level introduction to `Convolutional Neural Networks` using the `Keras` API implemented by the `TensorFlow` framework. It will discuss many common topics when working with Machine Learning and CNNs, but it will teach them in great detail. The structure of this notebook has been optimized for a learning objective rather than a programming/memory efficiency perspective.\n",
    "\n",
    "<img src=\"images/hoegaarden.jpg\" style=\"height:200px;\">\n",
    "<caption><center> <u> Figure 2:</u> A Hoegaarden<br> </center></caption>\n",
    "\n",
    "<img src=\"images/tuborg.jpg\" style=\"height:200px;\">\n",
    "<caption><center> <u> Figure 3:</u> A Tuborg<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Version check\n",
    "Before doing any coding, it's always a good practice to ensure we are running the correct version of the packages. This notebook has been tested to run with TensorFlow v2.9.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1) Importing data\n",
    "The first step of any Machine Learning project is to examine the available data in order to get a better understanding of it. So let's do that!\n",
    "\n",
    "A folder called `data` has been provided with 40 images, 20 images of a Hoegaarden and 20 images of a Tuborg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make use of a framework called `Matplotlib` in order to visualize the data, which is a common Python framework for plotting data. We will use the `pyplot` module which provides an interface similar to the one found in MATLAB. We'll also use the `image` module which will help to import a single image from disk so we can show it in the notebook. Furthermore we'll instruct Matplotlib to embed its output into the Jupyter Notebook using the `inline` command.\n",
    "\n",
    "We'll import all of these dependencies in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the plotting framework and necessary methods, let's plot a single data point in order to see how it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('data/hoegaarden/IMG_6603.JPG')\n",
    "plt.imshow(img)\n",
    "print(\"Image size: \", img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the raw data available to us are a bunch of images with the size 3024x4032 pixels and 3 color channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Preprocessing the data\n",
    "As we saw in the previous section, the images are 4032x3024 pixels big, which means they are just the raw images taken by a smartphone. In order to prevent your computer from melting down and running of out memory when training the CNN, then we should scale down these images down before using them for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**In the following cell, you should perform the following steps:**\n",
    "\n",
    "Create a python list called `images_paths_orig` which should contain all the paths to images found in the `data` folder. The resulting list should be similar to the following:\n",
    "`['data/hoegaarden/IMG_6603.JPG', 'data/tuborg/IMG_6604.JPG', ...]`\n",
    "\n",
    "A few hints to help you on the way:\n",
    "- Use the `listdir` to list out all the files in a directory\n",
    "- Python lists have a method called `append`\n",
    "- First loop over all the file names in `data/tuborg/` and simply concatenate the file name with the absolute path like so `\"data/tuborg/\" + file_name`. Afterwards do the same for `data/hoegaarden/`\n",
    "- Write `print(images_paths_orig)` in order to have the contents written out for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "images_paths_orig = []\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of paths to all the images, let's scale them down to a more appropiate size. You will implement this logic in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**In the following cell, you should perform the following steps:**\n",
    "\n",
    "Loop over every path in `images_paths_orig` and perform the following actions:\n",
    "\n",
    "1. Load the image into memory \n",
    "2. Scale it down to 200x150px\n",
    "3. Create a new path for the scaled image. It should have the same folder structure, but in a folder called `tmp` instead of `data`. An example of such a new path could be `'tmp/hoegaarden/IMG_6603.JPG'`\n",
    "4. Save the resized image to this new path\n",
    "5. Append this new path to the list `images_paths_resized`\n",
    "\n",
    "Hints:\n",
    "- Use the imported `Image` for loading the image from disk into memory\n",
    "- The `Image` object has a `resize` method\n",
    "- Use the `replace` method on a String in order to replace the word `data` with the word `tmp` in the path string\n",
    "- The `Image` object has a `save` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIL stands for `Python Imaging Library` which is the standard library for dealing with images in Python.\n",
    "from PIL import Image\n",
    "from os import makedirs\n",
    "\n",
    "new_width  = 200\n",
    "new_height = 150\n",
    "images_paths_resized = []\n",
    "\n",
    "makedirs(\"tmp/tuborg\", exist_ok=True)\n",
    "makedirs(\"tmp/hoegaarden\", exist_ok=True)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Loading the data\n",
    "Now that all the images have been preprocessed, then we are ready to train with them. However, before we continue, there are two important Machine Learning concepts worth explaining first:\n",
    "\n",
    "1. Splitting the data into a training and testing set\n",
    "2. One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test data\n",
    "\n",
    "Let's say that we have the dataset seen in Table 1. This is a list of 10 images with a corresponding label indicating whether there's a dog in the image or not.\n",
    "\n",
    "You start by building a ML model and then train it on all 10 images to detect whether there is a dog in the image or not. Afterwards you are curious to see how well it learned to detect dogs, so to test it you give the model `img1.jpg` and it correctly outputs that the image has a dog in it. Just to confirm the results, then you also ask the model to classify the other 9 images and it gets everything correct.\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<center><b>üö´üö´üö´This is bad practice and is the biggest Machine Learning sin everüö´üö´üö´</b></center>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-yw4l\">image</th>\n",
    "    <th class=\"tg-yw4l\">dog?</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img1.jpg<br></td>\n",
    "    <td class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img2.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img3.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img4.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img5.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img6.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img7.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img8.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img9.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img10.jpg</td>\n",
    "    <td class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<caption><center> <u> Table 1:</u> An fictional dataset of images and a label indicating whether the image contains a dog<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why this is a bad practice is because the Machine Learning algorithm has simply memorized all the images it has seen. It's just like if you are studying for a math exam and memorizing all the assignments you are studying at home. At the exam itself, then you are presented with the exact same assignments you were studying at home.\n",
    "\n",
    "Instead of asking the model to classify images that it has already seen, then you need to ask the model to classify images that it has never seen before. You can achieve this by only training the model on part of the original data and save the rest of the data for testing, as seen in Figure 4.\n",
    "\n",
    "<img src=\"images/train_test.png\" style=\"height:200px;\">\n",
    "<caption><center> <u> Figure 4:</u> Illustration of how the full dataset is split into 2 parts; one for training and one for testing<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we split the data with a 70%/30% split, similar to the green/blue split in Table 2. This means the Machine Learning model is allowed to learn from 70% of the data, but once you need to test the model, then you test it against the 30% data it has never seen. \n",
    "\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-yw4l\">image</th>\n",
    "    <th class=\"tg-yw4l\">dog?</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">img1.jpg<br></td>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">img2.jpg</td>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">img3.jpg</td>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">img4.jpg</td>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">img5.jpg</td>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">img6.jpg</td>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">img7.jpg</td>\n",
    "    <td bgcolor=\"#c9daf8\" class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#d9ead3\" class=\"tg-yw4l\">img8.jpg</td>\n",
    "    <td bgcolor=\"#d9ead3\" class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#d9ead3\" class=\"tg-yw4l\">img9.jpg</td>\n",
    "    <td bgcolor=\"#d9ead3\" class=\"tg-yw4l\">üö´</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td bgcolor=\"#d9ead3\" class=\"tg-yw4l\">img10.jpg</td>\n",
    "    <td bgcolor=\"#d9ead3\" class=\"tg-yw4l\">üê∂</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<caption><center> <u> Table 2:</u> The dataset has now been split into a training (blue) and test set (green)<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding\n",
    "One-hot encoding is a technique used to represent categorial data. So what is categorial data? It's data has a finite list of potential values. It's much easier to explain through an example, so let's do that!\n",
    "\n",
    "Imagine we are building an image classifier to detect which city is shown in the image. We've gathered the following imaginary dataset.\n",
    "\n",
    "<br/>\n",
    "\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}\n",
    ".tg .tg-yw4l{vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "  <tr>\n",
    "    <th class=\"tg-yw4l\">image</th>\n",
    "    <th class=\"tg-yw4l\">city</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img1.jpg<br></td>\n",
    "    <td class=\"tg-yw4l\">Paris</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img2.jpg</td>\n",
    "    <td class=\"tg-yw4l\">Copenhagen</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img3.jpg</td>\n",
    "    <td class=\"tg-yw4l\">Copenhagen</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img4.jpg</td>\n",
    "    <td class=\"tg-yw4l\">Chicago</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-yw4l\">img5.jpg</td>\n",
    "    <td class=\"tg-yw4l\">Paris</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<caption><center> <u> Table 3:</u> An fictional dataset of images and a label indicating which city is shown in the corresponding image<br> </center></caption>\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways we could encode the labels seen in Table 3. One of the first ideas that comes to mind would be to store the labels as a list of strings.\n",
    "\n",
    "```\n",
    "labels = [\"Paris\", \"Copenhagen\", \"Copenhagen, \"Chicago\", \"Paris\"]\n",
    "```\n",
    "\n",
    "Unfortunately Machine Learning models only work with numbers, so we need to convert that list into numbers. Let's use the notation that that `Paris=1`, `Copenhagen=2` and `Chicago=3`. This would update our list of labels to be:\n",
    "\n",
    "```\n",
    "data = [1, 2, 2, 3, 1]\n",
    "```\n",
    "\n",
    "This representation of labels is technically feasible to train a ML model, but unfortunately it does not perform very well. It's hard for the model to calculate these relatively huge numerical difference, which will only grow proportionally to the amount of possible values (fx if there are 200 cities, then the max value will be 200). A fundamental part of neural networks is derivities and they will have a much better effect working on smaller values.\n",
    "\n",
    "A representation that has shown itself useful in this regard is called one-hot encoding. The idea is that instead of representing a data point as a single value, then it should be represented by a list of zeroes where a single element is 1.\n",
    "\n",
    "In the case of the data above, then the encoding could for example be:\n",
    "\n",
    "```\n",
    "Paris      =¬†[1, 0, 0]\n",
    "Copenhagen =¬†[0, 1, 0]\n",
    "Chicago    =¬†[0, 0, 1]\n",
    "```\n",
    "\n",
    "This means our data variable would be a list of lists, also known as a matrix:\n",
    "\n",
    "```\n",
    "data = [[1, 0, 0], \n",
    "        [0, 1, 0], \n",
    "        [0, 1, 0], \n",
    "        [0, 0, 1], \n",
    "        [1, 0, 0]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Figure 5 and Figure 6 show some other examples of representing categorial data as one-hot encoded data.\n",
    "\n",
    "<img src=\"images/one_hot_1.png\" style=\"height:200px;\">\n",
    "<caption><center> <u> Figure 5:</u> Illustration of one-hot encoding fruit data<br> </center></caption>\n",
    "\n",
    "<img src=\"images/one_hot_2.png\" style=\"height:200px;\">\n",
    "<caption><center> <u> Figure 6:</u> Illustration of one-hot encoding color data<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**In the following cell, you should perform the following steps:**\n",
    "\n",
    "Loop over each path and its corresponding index in `images_paths_resized` and perform the following tasks:\n",
    "1. Load the image into memory using the `load_img` method\n",
    "2. Convert the image data into a matrix using the `img_to_array` method\n",
    "3. Assign the matrix with the image data to the `i`'th index in the variable `x`\n",
    "4. If the image is a Tuborg, then the `i`'th index in `y` should be set to 0. Otherwise 1.\n",
    "\n",
    "Once the `x` and `y` variables have been filled, then use the `to_categorical` method on `y` in order to one-hot encode it. Remember to store the output of this method back into the `y` variable.\n",
    "\n",
    "Hints:\n",
    "- Use the `enumerate` method on a list in order get tuples containing the element and its corresponding index\n",
    "- Python has an operator `in` which can be used on strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "num_samples = len(images_paths_resized)\n",
    "color_channels = 3\n",
    "x = np.zeros((num_samples, new_height, new_width, color_channels))\n",
    "y = np.zeros((num_samples, 1))\n",
    "num_classes = 2\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the image data and labels loaded into memory in a format we can work with, then we need to split it into a training set and test set. This can easily be done using the `train_test_split` from the scikit-learn framework. We give it a random seed to ensure consistent results whenever this code is run. The default split is 25% data for the test set.\n",
    "\n",
    "We also need to apply another trick on the raw image data. We need to normalize it, which means that all the values will be between 0 and 1. This to ensure the model works with smaller numbers like one-hot encoding, which will help the model to learn much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "# Normalizing the image data\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Building the model\n",
    "Now comes the fun part of actually building the `Convolutional Neural Network` üéâ \n",
    "\n",
    "A CNN consists of many different working parts, the two most important parts being:\n",
    "- Fully connected layer (also known as `Dense` layer in the Keras API)\n",
    "- Convolutional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layer\n",
    "Let's try to look at a fully connected layer from an outside-in perspective. A small neural network can be seen in the following Figure 7. Think of the red layer as the raw image data of either a Hoegaarden or Tuborg, the blue layer is a fully-connected layer and the green layer is the one-hot encoded output.\n",
    "\n",
    "A fully connected layer consists of a bunch of individual neurons which are all connected to the input from the previous layer. As seen in Figure 7, all the neurons in the blue layer are connected to all the input nodes in the red layer.\n",
    "\n",
    "<img src=\"images/neural_net.png\" style=\"height:200px;\">\n",
    "<caption><center> <u> Figure 7:</u> A small neural network consisting of a single hidden layer with 4 units<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper and see what happens in a single neuron in the fully connected layer. Take a look at Figure 8 and then we'll review it step by step:\n",
    "\n",
    "1 - First the input from the previous layer is passed to the neuron, let's denote this input as `x`. These are illustrated as orange circles in Figure 8. There are 3 inputs to the neuron in Figure 8, which means x is actually a list of 3 elements: \n",
    "\n",
    "> x = [x_1, x_2, x_3]\n",
    "\n",
    "2 - The neuron has a list of parameters known as weights, `w`, which are parameters that the neuron has learned through training. When you train a neural network, then it is actually these weights that you adjust in order to get the correct output. The neuron has a specific weight for each input, in the case of Figure 8, then the weights would be:\n",
    "\n",
    "> w = [w_1, w_2, w_3] = [0.7, 0.6, 1.4]\n",
    "\n",
    "3 - Next step is for the neuron to multiply `x` and `w` and sum them up. So the calculation of the neuron so far is: \n",
    "\n",
    "> $\\sum$ wx = $\\sum$ [w_1, w_2, w_3] * [x_1, x_2, x_3] = w_1 $*$ x_1 + w_2 $*$ x_2 + w_3 $*$ x_3\n",
    "\n",
    "4 - The neuron has another parameter besides the weights called the bias, also learned through training, which is represents what is not modelled by the input. This will cause a better prediction of the output. The purpose of the bias is  similar to the term `b` in the classic linear equation `y = ax + b`. The current calculation of the neuron looks like the following:\n",
    "\n",
    "> w_1 $*$ x_1 + w_2 $*$ x_2 + w_3 $*$ x_3  + b\n",
    "\n",
    "5 - The last step for a neuron is to pass the calculation through an activation function. There exists many different types, but in this notebook we will make use of one called `relu`. This means that the output of the neuron in Figure 8 is the following:\n",
    "\n",
    "> output = relu(w_1 $*$ x_1 + w_2 $*$ x_2 + w_3 $*$ x_3  + b)\n",
    "\n",
    "<img src=\"images/neuron.gif\" style=\"height:200px;\">\n",
    "<caption><center> <u> Figure 8:</u> Illustration of what goes on inside a single neuron<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer\n",
    "The structure of a convolutional layer is quite different from a fully-connected layer. We won't go into much detail, but only give a quick intuition of what it does.\n",
    "\n",
    "Convolutional layers has become the standard to use when dealing with images. The reason for this is because it \"scans\" an image and reuses its learnings across the whole image. \n",
    "\n",
    "Let's say  you have a bunch of training images with a dog in the right corner of all the images. If you were to use a neural network only consisting of fully-connected layers, then it would not learn how to recognize the dog if it was placed in the top left corner of the image. However if you use convolutional layers, then it will reuse it learnings and realize that it's a dog even though it's placed in the top left corner of the image.\n",
    "\n",
    "The following Figure 9 shows an image (the red, green and blue layers in the top) being scanned by a conlutional layer.\n",
    "\n",
    "<img src=\"images/conv_layer.gif\" style=\"height:300px;\">\n",
    "<caption><center> <u> Figure 9:</u> A a convolution over an image with a single color channel<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**In the following cell, you should perform the following steps in the order specified:**\n",
    "- Add a `Activation` layer with a `relu` activation to the model\n",
    "- Add a `MaxPooling2D` layer to the model with a pool size of `(2,2)` and strides of `(2,2)`\n",
    "- Add a `Dropout` layer with a dropout rate of `0.5`\n",
    "- Add a `Conv2D` layer with 64 filters and a kernel size of `(3,3)`\n",
    "- Add a `Activation` layer with a `relu` activation to the model\n",
    "- Add a `MaxPooling2D` layer to the model with a pool size of `(2,2)` and strides of `(2,2)`\n",
    "- Add a `Dropout` layer with a dropout rate of `0.5`\n",
    "- Add a `Flatten` layer\n",
    "- Add a `Dense` layer with 256 hidden units\n",
    "- Add a `Activation` layer with a `relu` activation to the model\n",
    "- Add a `Dropout` layer with a dropout rate of `0.5`\n",
    "- Add a `Dense` layer with 2 hidden units\n",
    "- Add a `Activation` layer with a `softmax` activation to the model\n",
    "\n",
    "You can find the necessary documentation for the different layer types here:\n",
    "- [Activation documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Activation)\n",
    "- [MaxPooling2D documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "- [Dropout documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "- [Conv2D documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "- [Flatten documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
    "- [Dense documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=x[0].shape))\n",
    "\n",
    "### START CODE HERE ### \n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Training the model\n",
    "Now that the model architecture has been defined, then it's time for the training. Based on the description earlier of fully-connected layers, then a neural network simply consists of a lot of small float variables known as weights and biases. When training a neural network, then these weights and biases have to be tuned to the perfect values in order to get the correct output. The training process takes care of tuning these variables through a process called backpropagation with an approach called gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loss function\n",
    "Before moving on, first we need to discuss something called the loss function. This is a mathematical equation, just like `y = ax + b`, which defines how accurate the output of a model is compared to the expected output:\n",
    "\n",
    "> Loss function = $\\mathcal{L}$($\\hat{y}$, y)\n",
    "\n",
    "> where **$\\hat{y}$** is the predicted value by the model and **y** is the real value provided in the training data.\n",
    "\n",
    "The loss function calculates how different **$\\hat{y}$** and **y** are. If they are an exact match, then the loss will have a value of $\\mathcal{L}$($\\hat{y}$, y) = 0. If they are very different, then the loss will be a big numerical value.\n",
    "\n",
    "That means, the lower the loss, the better the model is performing. And this is really important, because this gives us a value to measure on how well the model is performing. So if we adjust the parameters in the neural network, then we can measure if these changes made the model better or worse.\n",
    "\n",
    "In our case of beer classification, we will use a loss function called binary crossentropy. There exist a lot of different loss functions depending on the use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation and gradient descent\n",
    "The essense of backpropagation is based on derivatives. It will calculate the derivate of the loss function and determine towards which direction that the weights and biasses should be updated.\n",
    "\n",
    "Let's try to look at an example. Let's assume that the loss function that we've chosen to use is a quadratic function, which depends on the weights `w` and biasses `b` in the neural network. The graphical representation of this quadratic function can be seen in Figure 10. In Figure 10, the variable `x` can be considered a combination of `w` and `b`.\n",
    "\n",
    "Both `w` and `b` are initialized randomly when the training begins. Such a random state could for example at the top left of the graph. Taking the derivative at this point, the gradient descent can figure out that it should take a small step to the right in order to reduce the loss (thus making the model more accurate). It repeats this process over and over for multiple iterations, until the gradient descent has converged at the bottom and reached the optimal values for `w` and `b`.\n",
    "\n",
    "Figure 11 shows how the parameters are being updated for each iteration of gradient descent and ends up converging with the lowest loss possible.\n",
    "\n",
    "<img src=\"images/gradient_descent.jpg\" style=\"height:300px;\">\n",
    "<caption><center> <u> Figure 10:</u> The quadratic loss as a function based on the neural network parameters `x`.<br> </center></caption>\n",
    "\n",
    "<img src=\"images/backprop.gif\" style=\"height:250px;\">\n",
    "<caption><center> <u> Figure 11:</u> An illustration of a network training. The loss (also known as error) can be seen in the right corner.<br> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Trains the model\n",
    "model.compile(loss=binary_crossentropy, optimizer=Adam(lr=0.00001), metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Evaluating the model\n",
    "As seen from the output above while training the model, the accuracy on the training data increased steadily over time. However, when measuring the real accuracy of a model, then it needs to be against the test data as discussed previously.\n",
    "\n",
    "In total we have 40 data sample and 25% was set aside for the test set, which means we have 10 images to test on.\n",
    "\n",
    "The final accuracy test is quite simple:\n",
    "> The model will be given a bunch of images that it has never seen before and asked to classify them as either a Turborg or Hoegaarden. If it correctly classifies for example 9 out of 10 images, then it will get an accuracy of 90%. \n",
    "\n",
    "Implementing this evaluation is very simply thanks to useful method in the Keras API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output above, the accuracy of the model managed to achieve an accuracy above 80%! üéâ This result will vary from time to time since we haven't given any fixed seed to the random number generator.\n",
    "\n",
    "If the model would have learned nothing at all, then it would be guessing randomly, giving an accuracy of approximately 50 % since there are only 2 beers to guess between. If there had been 3 beers, then it would have had a guessing accuracy of 33%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Next steps - Deployment\n",
    "Congratulations on reaching it to the end! You now have a fully functional CNN for classifying beers. The next step is to export the model and deploy this model somewhere so it can be used in production!\n",
    "\n",
    "- One option could be to create an iOS app and embed the model using `CoreML`: https://developer.apple.com/documentation/coreml\n",
    "- Another option could be to setup a simple web server and expose the model through a web API: https://blog.keras.io/building-a-simple-keras-deep-learning-rest-api.html\n",
    "\n",
    "If you're up to the challenge, then you can also try to collect images of a third beer and update the CNN architecture to handle a third possible output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Figure 1: https://www.reddit.com/r/Denmark/comments/626pl6/personlig_pleje_i_netto/\n",
    "- Figure 2: https://www.belgianbeerz.com/products/hoegaarden-75-cl?variant=1069873317\n",
    "- Figure 3: https://www.bestiloghent.dk/produkt?id=29914\n",
    "- Figure 4: http://scott.fortmann-roe.com/docs/MeasuringError.html\n",
    "- Figure 5: https://chrisalbon.com/machine_learning/preprocessing_structured_data/one-hot_encode_nominal_categorical_features/\n",
    "- Figure 6: https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding\n",
    "- Figure 7: https://medium.com/@curiousily/tensorflow-for-hackers-part-iv-neural-network-from-scratch-1a4f504dfa8\n",
    "- Figure 8: https://harishnarayanan.org/writing/artistic-style-transfer/\n",
    "- Figure 9: https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0\n",
    "- Figure 10: https://www.quora.com/Does-Gradient-Descent-Algo-always-converge-to-the-global-minimum\n",
    "- Figure 11: https://www.codeproject.com/articles/175777/financial-predictor-via-neural-network\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
